{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57d7193-8e37-41dd-99ed-06c669ca9159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple MPS (Metal Performance Shaders)\n",
      "Original video FPS: 25.153309367731023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 09:57:15.834 Python[93929:9005138] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-04-16 09:57:15.834 Python[93929:9005138] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import openpifpaf\n",
    "import torch\n",
    "\n",
    "# Path to your video file\n",
    "video_path = '../input/video/right_profile_1.mov'\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Using Apple MPS (Metal Performance Shaders)\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# Create a Predictor instance with the desired model checkpoint\n",
    "predictor = openpifpaf.Predictor(checkpoint='shufflenetv2k16')\n",
    "\n",
    "# Define the COCO keypoint connections (skeleton)\n",
    "SKELETON_CONNECTIONS = [\n",
    "    (0, 1), (0, 2), (1, 3), (2, 4),  # Head to shoulders and shoulders to elbows\n",
    "    (3, 5), (4, 6),  # Elbows to wrists\n",
    "    (5, 7), (7, 9), (6, 8), (8, 10),  # Arms to hands\n",
    "    (5, 11), (6, 12),  # Arms to hips\n",
    "    (11, 13), (12, 14),  # Hips to knees\n",
    "    (13, 15), (14, 16)  # Knees to ankles\n",
    "]\n",
    "\n",
    "# Open the video file using OpenCV\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video {video_path}\")\n",
    "    exit(1)\n",
    "    \n",
    "# Get video properties\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(f\"Original video FPS: {fps}\")\n",
    "\n",
    "# Define how many frames to skip\n",
    "# For example, to process 1 out of every 5 frames:\n",
    "frame_skip = 5\n",
    "frame_count = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Process only every Nth frame (where N = frame_skip)\n",
    "    if frame_count % frame_skip == 0:\n",
    "        # OpenPifPaf expects an RGB image (OpenCV loads images in BGR format)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Run the predictor on the current frame\n",
    "        predictions, _, _ = predictor.numpy_image(rgb_frame)\n",
    "        \n",
    "        # Draw the detected poses on the original frame\n",
    "        for ann in predictions:\n",
    "            keypoints = ann.data\n",
    "            \n",
    "            # Draw keypoints\n",
    "            for x, y, conf in keypoints:\n",
    "                if conf > 0.5:  # Only draw keypoints above a confidence threshold\n",
    "                    cv2.circle(frame, (int(x), int(y)), radius=5, color=(0, 255, 0), thickness=-1)\n",
    "            \n",
    "            # Draw skeleton (connecting lines between keypoints)\n",
    "            for p1_idx, p2_idx in SKELETON_CONNECTIONS:\n",
    "                if (keypoints[p1_idx, 2] > 0.5 and keypoints[p2_idx, 2] > 0.5):\n",
    "                    p1 = (int(keypoints[p1_idx, 0]), int(keypoints[p1_idx, 1]))\n",
    "                    p2 = (int(keypoints[p2_idx, 0]), int(keypoints[p2_idx, 1]))\n",
    "                    cv2.line(frame, p1, p2, color=(0, 0, 255), thickness=2)\n",
    "        \n",
    "        # Display the frame with pose estimates\n",
    "        cv2.imshow('OpenPifPaf Pose Estimation', frame)\n",
    "        \n",
    "        # Control display speed (adjust the wait time if needed)\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Increment frame counter\n",
    "    frame_count += 1\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "py39_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
